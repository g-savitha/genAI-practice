{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69954c2d",
   "metadata": {},
   "source": [
    "## Stemming\n",
    "\n",
    "Stemming is the process of reducing a word to its setem that affixes to suffixes and prefixes to the roots of wrods known as lemma. Stemming is important in Natural Language understanding (NLU) and NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73474581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Problem\n",
    "# comments of a prodcut is a positive review or negative review\n",
    "\n",
    "# Reviews -> eating, eat, eaten  -> all these words mean the same 'eat' these are not going to affect the decision of positive or negative\n",
    "# we dont need all these words which mean the same -> as each word reprents a vector\n",
    "#  stemming helps us to remove the suffixes and prefixes and helps to find the root word\n",
    "\n",
    "words = ['eating', 'eats', 'writing', 'writes', 'programming',\n",
    "         'programs', 'history', 'finally', 'finalize']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282cc5ce",
   "metadata": {},
   "source": [
    "## Porter Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b022947f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "stemming = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ede021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating----->eat\n",
      "eats----->eat\n",
      "writing----->write\n",
      "writes----->write\n",
      "programming----->program\n",
      "programs----->program\n",
      "history----->histori\n",
      "finally----->final\n",
      "finalize----->final\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word + '----->' + stemming.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907c704c",
   "metadata": {},
   "source": [
    "in the above example \n",
    "\n",
    "the history is changed to histori. the meaning of the word is changed\n",
    "\n",
    "this is sometimes the main disadavantage of stemming -> this can be fixed with lemmatization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42de25eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'congratul'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem('congratulations')\n",
    "\n",
    "# same with this example as well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d529b46b",
   "metadata": {},
   "source": [
    "### RegexpStemmer Class\n",
    "\n",
    "NLTK has RegexpStemmer class with the help of which we can easily implement regular expression stemmer algos. It basically takes a single regexp and removes any prefix or suffix that matches the expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85423f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import RegexpStemmer\n",
    "\n",
    "# this says if you find a word ending with 'ing' or 's' or 'e' or 'able' remove that\n",
    "reg_stemmer = RegexpStemmer('ing$|s$|e$|able$', min=4)\n",
    "reg_stemmer.stem('eating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db62389c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ingeat'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemmer.stem('ingeating')  # removes only ending ing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ae4625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to remove from starting change the regexp\n",
    "# this removes the occurence of ing from the entire word\n",
    "reg_stemmer = RegexpStemmer('ing|s$|e$|able$', min=4)\n",
    "reg_stemmer.stem('ingeating')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b479921",
   "metadata": {},
   "source": [
    "### Snowball Stemmer\n",
    "\n",
    "- Performs better than PorterStemmer -> gives better accuracy(better output of words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a81049c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "snowball_stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe20bdc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating----->eat\n",
      "eats----->eat\n",
      "writing----->write\n",
      "writes----->write\n",
      "programming----->program\n",
      "programs----->program\n",
      "history----->histori\n",
      "finally----->final\n",
      "finalize----->final\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+'----->'+snowball_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f663d3",
   "metadata": {},
   "source": [
    "history value is same on PorterStemmer and SnowballStemmer\n",
    "\n",
    "ps: history value can be fixed by lemmatization\n",
    "\n",
    "comparing the differences between few words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5394bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fairli\n",
      "sportingli\n",
      "fair\n",
      "sport\n"
     ]
    }
   ],
   "source": [
    "# porter stemmer\n",
    "print(stemming.stem('fairly'))\n",
    "print(stemming.stem('sportingly'))\n",
    "\n",
    "# snowball stemmer\n",
    "\n",
    "print(snowball_stemmer.stem('fairly'))\n",
    "print(snowball_stemmer.stem('sportingly'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2057b323",
   "metadata": {},
   "source": [
    "stemming is used majorly in text pre-processing -> helps us to convert words to vectors in an efficient way\n",
    "\n",
    "*disadvantage of stemming:*\n",
    "- it doesnt give proper output for few words. it changes the meaning completely\n",
    "- history ---> histori\n",
    "- goes ---> goe (even with snowballstemmer)\n",
    "\n",
    "for usecases like chatbot, only stemming is not helpful , we need techniques like lemmatization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95fb091",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd28ecac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
